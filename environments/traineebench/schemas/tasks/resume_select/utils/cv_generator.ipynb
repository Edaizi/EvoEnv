{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/yxm/code/InternBench\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "grandparent_dir = current_dir.parent.parent.parent.parent\n",
    "print(grandparent_dir)\n",
    "sys.path.append(str(grandparent_dir))\n",
    "\n",
    "from agents.base_agent import get_config\n",
    "\n",
    "\n",
    "model_name, api_key, base_url, proxy_url = get_config(\"gemini-2.5-flash\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reponse(prompt):\n",
    "    try_time = 0\n",
    "    while try_time<3:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\":prompt,\n",
    "                }\n",
    "            ],\n",
    "            temperature = 1 # 自行修改温度等参数\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}. Retrying... ({try_time+1}/3)\")\n",
    "            try_time += 1\n",
    "\n",
    "    return \"Error: Failed to get response after 3 attempts.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "## Alex Chen\n",
    "Software Engineer | (555) 123-9876 | alex.chen@email.com | linkedin.com/in/alex-chen\n",
    "\n",
    "### Summary\n",
    "Experienced and results-oriented senior machine learning engineers who develop, deploy, and optimize large-scale artificial intelligence systems and applications. Ph.D. in Computer Science with a strong theoretical foundation in **Large Language Models (LLMs)**, deep learning, and natural language processing. Proven ability to lead projects, collaborate cross-functionally, and deliver innovative solutions that drive business value. Seeking a challenging role to leverage expertise in cutting-edge AI technologies.\n",
    "\n",
    "---\n",
    "\n",
    "### Education\n",
    "**Massachusetts Institute of Technology (MIT)**\n",
    "* **Doctor of Philosophy (Ph.D.) in Computer Science** (2017-2021)\n",
    "    * *Dissertation Focus:* Scalable Training and Optimization of Transformer-based Large Language Models.\n",
    "* **Master of Science (M.S.) in Computer Science** (2014-2017)\n",
    "\n",
    "**Peking University**\n",
    "* **Bachelor of Science (B.S.) in Computer Science** (2010-2014)\n",
    "    * *GPA:* 3.9/4.0\n",
    "\n",
    "---\n",
    "\n",
    "### Experience\n",
    "**TechGlobal Innovations - Senior Machine Learning Engineer** | Boston, MA\n",
    "* **October 2021 – Present (4+ Years)**\n",
    "* Led a team of 4 engineers in the development and production deployment of a proprietary 7-billion parameter **LLM** for enterprise knowledge retrieval, reducing internal query resolution time by **40%**.\n",
    "* Designed and implemented MLOps pipelines using Kubernetes and AWS SageMaker to ensure continuous integration and deployment of AI models.\n",
    "* Pioneered the use of **RAG (Retrieval-Augmented Generation)** architectures to enhance model accuracy and factuality on domain-specific datasets.\n",
    "* Collaborated with product managers to translate business needs into technical specifications for new AI-driven features.\n",
    "\n",
    "**AI Research Labs - Research Intern** | Palo Alto, CA\n",
    "* **June 2018 – September 2020 (2 Years)**\n",
    "* Conducted fundamental research on model compression techniques (**Quantization and Pruning**) for deployment on edge devices, achieving a **3x** reduction in model size with minimal performance drop.\n",
    "* Published **3 papers** at top-tier AI conferences (NeurIPS, ICML).\n",
    "* Mentored junior researchers on deep learning frameworks and experimental design.\n",
    "\n",
    "---\n",
    "\n",
    "### Skills\n",
    "* **Large Language Models (LLMs):** Transformer Architecture, Fine-tuning (LoRA), Prompt Engineering, RAG, Llama-Index, LangChain.\n",
    "* **Programming & Frameworks:** Python (PyTorch, TensorFlow), Java, C++, Node.js, Git.\n",
    "* **Cloud & DevOps:** AWS (S3, EC2, SageMaker), Docker, Kubernetes, CI/CD.\n",
    "* **Databases & Tools:** SQL, NoSQL (MongoDB), Linux.\n",
    "\n",
    "---\n",
    "\n",
    "### Projects\n",
    "**Personal Project: LLM-Powered Code Review Assistant**\n",
    "* Developed a Python application using OpenAI's API fine-tuned on code review datasets to automatically suggest improvements and detect common bugs in pull requests, integrating with GitHub Actions.\n",
    "\n",
    "---\n",
    "\n",
    "### Achievements\n",
    "* **MIT Graduate Student Award for Academic Excellence** (2018)\n",
    "* Recipient of the **TechGlobal Innovation Award** for the LLM deployment project (2022).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "generate resume 31 for Noah Brown\n"
     ]
    }
   ],
   "source": [
    "position = [\"Software Engineer\", \"Software Developer\", \"Algorithm Researcher\"]\n",
    "educations = [\"Bachelor's\", \"Master's\", \"Doctoral\"]\n",
    "major = [\"Computer Science\", \"Computer Engineering\", \"Software Engineering\", \"Mathematics\", \"Electrical Engineering\", \"Data Science\", \"Control Science\"]\n",
    "years_of_work_experience = [\"Not yet graduated\", \"1 year\", \"2 years\", \"3 years\", \"4 years\", \"5 years\", \"6 years\", \"7 years\", \"8 years\", \"9 years\", \"10 years\"]\n",
    "skills4Engineer = [\"AWS\", \"Docker\", \"Kubernetes\", \"Python\", \"C++\", \"Java\", \"Node.js\", \"SQL\", \"PostgreSQL\", \"MySQL\", \"MongoDB\", \"Redis\", \"Git\", \"CI/CD\"]\n",
    "skills4Researcher = [\"Large Language Models\", \"Fine-tuning\", \"Prompt Engineering\", \"RAG\", \"AI Agent\", \"LangChain\", \"Pre-training\", \"Post-training\", \"Autonomous Driving\", \"Computer Vision\", \"NLP\", \"Reinforcement Learning\", \"Python\", \"C++\",\"Deep Research Agent\", \"LLM tool use\",]\n",
    "\n",
    "name_list = [\n",
    "    \"Aaliyah Thompson\", \"Lin Yan\",\n",
    "    \"Aarav Patel\", \"Li Tao\",\n",
    "    \"Alex Chen\", \"Liu Wei\",\n",
    "    \"Ana Maria Gonzalez\", \"Lu Hui\",\n",
    "    \"Ananya Bose\", \"Lu Jian\",\n",
    "    \"Andrei Popescu\", \"Luo Jie\",\n",
    "    \"Arjun Singh\", \"Lv Yang\",\n",
    "    \"Avery Williams Bootcamp\",\n",
    "    \"Blake Anderson Bootcamp\", \"Marta Nowak\",\n",
    "    \"Charlie Brown Bootcamp\", \"Mason Martinez\",\n",
    "    \"Chen Tao\", \"Mateo Silva\",\n",
    "    \"Christopher Brown\", \"Mei Chen\",\n",
    "    \"Cui Xue Mei\", \"Natalia Kovalenko\",\n",
    "    \"Deng Cheng\", \"Neha Verma\",\n",
    "    \"DeShawn Robinson\", \"Nikhil Mehta\",\n",
    "    \"Diego Lopez\", \"Noah Brown\",\n",
    "    \"Ding Shu Zhen\", \"Noah Garcia\",\n",
    "    \"Diya Reddy\", \"Noah Martinez\",\n",
    "    \"Drew Martinez Bootcamp\", \"Olivia Martinez\",\n",
    "    \"Ekaterina Petrova\", \"Peyton Clark Bootcamp\",\n",
    "    \"Emerson Scott Bootcamp\", \"Piotr Kowalski\",\n",
    "    \"Emily Zhang\", \"Pooja Sharma\",\n",
    "    \"Emma Anderson\", \"Rahul Joshi\",\n",
    "    \"Emma Davis\", \"Reese Campbell Bootcamp\",\n",
    "    \"Emma Smith\", \"Siddharth Menon\",\n",
    "    \"Ethan Anderson\", \"Skylar White Bootcamp\",\n",
    "    \"Ethan Garcia\", \"Sofia Martinez\",\n",
    "    \"Ewa Wojcik\", \"Song Shu Ying\",\n",
    "    \"Feng Feng Ying\", \"Soo-Jin Kim\",\n",
    "    \"Finley Moore Bootcamp\", \"Sophia Davis\",\n",
    "    \"Harper Garcia Bootcamp\", \"Tan Rui\",\n",
    "    \"He Chen\", \"Tanvi Deshmukh\",\n",
    "    \"Hiroshi Tanaka\", \"Taylor Swift Bootcamp\",\n",
    "    \"Huang Bin\", \"Valentina Castro\",\n",
    "    \"Huang Ting Ting\", \"Vikram Malhotra\",\n",
    "    \"Huang Yu Zhen\", \"Wang Hai Yan\",\n",
    "    \"Ishaan Gupta\", \"William Lee\",\n",
    "    \"Jamie Davis Bootcamp\", \"William Wilson\",\n",
    "    \"Javier Hernandez\", \"Xiao Xia\",\n",
    "    \"Jessica Wilson\", \"Xu Gui Hua\",\n",
    "    \"John Smith\", \"Xu Yan\",\n",
    "    \"Jordan Lee Bootcamp\", \"Yang Shu Zhen\",\n",
    "    \"Keisha Washington\", \"Yao Xiu Ying\",\n",
    "    \"Kendall Wright Bootcamp\", \"Yuki Nakamura\",\n",
    "    \"Lai Li\", \"Zara Khan\",\n",
    "    \"Li Bing\", \"Zhang Gui Lan\",\n",
    "    \"Li Jie\", \"Zhang Hong\",\n",
    "    \"Li Mei\"\n",
    "]\n",
    "\n",
    "# 由于大模型每次rollout的名字都很像，甚至有重复，因此从tac的resume中拿到了这些不重复的名字。其中前30个名字已经使用过了。\n",
    "\n",
    "information = {}\n",
    "\n",
    "for i in range(30, 31):\n",
    "    name = name_list[i]\n",
    "    pos = random.choice(position)\n",
    "    edu = random.choice(educations)\n",
    "    major_choice = random.choice(major)\n",
    "    work_exp = random.choice(years_of_work_experience)\n",
    "    if pos in [\"Software Engineer\", \"Software Developer\"]:\n",
    "        skill_set = random.sample(skills4Engineer, k=2)\n",
    "    else:\n",
    "        skill_set = random.sample(skills4Researcher, k=2)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        角色设定： 你是一位资深的英文简历专家。\n",
    "        核心任务： 请严格参考提供的样例格式，生成一份完整的英文简历。\n",
    "        必填信息（请替换占位符）：\n",
    "            - 生成候选人信息: 名字为{name}, 职位为 {pos}\n",
    "            - 求职计划 (Summary)\n",
    "            - 教育背景 (Education)：学历必须是 {edu}，专业必须是 {major_choice}\n",
    "            - 工作经历 (Experience)：工作年限必须匹配 {work_exp}\n",
    "            - 技能 (Skills)：必须包含 {skill_set}\n",
    "        选填信息（可酌情生成）：\n",
    "            - 相关课程 (Relevant Coursework)\n",
    "            - 项目经验 (Projects)\n",
    "            - 个人成就 (Achievements)\n",
    "        输出要求：\n",
    "            注意：工作年限从毕业后第一份工作时间开始计算。工作经历和技能描述需要合理且真实。可以在经历中增加实习经历。\n",
    "            请直接输出简历内容，不允许有任何多余的文字、说明或解释。\n",
    "            严格使用 Markdown 格式输出，格式必须与以下样例保持一致:\n",
    "        样例: \n",
    "            {sample}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=====================================\")\n",
    "    print(f\"generate resume {i+1} for {name}\")\n",
    "    resume = generate_reponse(prompt)\n",
    "    candidate_name = resume.splitlines()[0].strip(\"# \").split(\"\\n\")[0]\n",
    "    info =  {\n",
    "        \"position\": pos,\n",
    "        \"education\": edu,\n",
    "        \"major\": major_choice,\n",
    "        \"work_experience\": work_exp,\n",
    "        \"ori_skills\": skill_set,\n",
    "    }\n",
    "    information[candidate_name] = info\n",
    "    with open(f\"../tasks/resume_select/resumes/{candidate_name}_resume.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(resume)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../tasks/resume_select/resume_info.json\", \"a\") as f:\n",
    "    json.dump(information, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills_from_resume(markdown_path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extracts skills from the '### Skills' section of a Markdown resume file.\n",
    "    It cleans the skills by removing parenthesized content, bold markers,\n",
    "    and category prefixes.\n",
    "\n",
    "    Args:\n",
    "        markdown_path: The absolute path to the Markdown resume file.\n",
    "\n",
    "    Returns:\n",
    "        A list of skills, or an empty list if the file or section is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(markdown_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {markdown_path}\")\n",
    "        return []\n",
    "\n",
    "    # Find the content under \"### Skills\" until the next \"###\" or end of file\n",
    "    skills_section_match = re.search(r\"### Skills\\n(.*?)(?=\\n###|\\Z)\", content, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    if not skills_section_match:\n",
    "        return []\n",
    "\n",
    "    skills_text = skills_section_match.group(1)\n",
    "\n",
    "    # 1. Remove content in parentheses (e.g., \"(Intermediate)\")\n",
    "    cleaned_text = re.sub(r'\\s*\\(.*?\\)', '', skills_text)\n",
    "\n",
    "    # 2. Remove bold markdown syntax (**)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    cleaned_text = cleaned_text.replace('*', '')\n",
    "    cleaned_text = cleaned_text.replace('---', '')\n",
    "    # print(cleaned_text)\n",
    "    \n",
    "    # 3. Remove category prefixes like \"Programming Languages:\"\n",
    "    cleaned_text = re.sub(r'^[^:]*:\\s*', '', cleaned_text, flags=re.MULTILINE)\n",
    "\n",
    "    # 4. Split by commas or newlines\n",
    "    skills_list = re.split(r'[\\n,]', cleaned_text)\n",
    "\n",
    "    # 5. Final cleanup: strip whitespace from each skill and remove empty strings\n",
    "    final_skills = []\n",
    "    for skill in skills_list:\n",
    "        skill = skill.strip('-')\n",
    "        skill = skill.strip('*')\n",
    "        skill = skill.strip(' ')\n",
    "        skill = skill.strip('.')\n",
    "        skill = skill.lower()\n",
    "        if skill != '':\n",
    "            final_skills.append(skill)\n",
    "\n",
    "    # print(final_skills)\n",
    "\n",
    "    return final_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../../tasks/resume_select/resume_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    information = json.load(f)\n",
    "\n",
    "for candidate_name in information.keys():\n",
    "    resume_path = f\"../../tasks/resume_select/resumes/{candidate_name}_resume.md\"\n",
    "    skills = extract_skills_from_resume(resume_path)\n",
    "    information[candidate_name][\"skills\"] = skills\n",
    "\n",
    "with open(\"../../tasks/resume_select/resume_info.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(information, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
